<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/01/07/hello-world/" class="article-date">
  <time class="dt-published" datetime="2025-01-07T03:07:26.655Z" itemprop="datePublished">2025-01-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/01/07/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/01/07/hello-world/" data-id="cm5lwfkmf0000t4bq899k9q5w" data-title="Hello World" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-CC11-Hessian矩阵" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/12/17/CC11-Hessian%E7%9F%A9%E9%98%B5/" class="article-date">
  <time class="dt-published" datetime="2024-12-16T16:00:00.000Z" itemprop="datePublished">2024-12-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/">微积分</a>►<a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/12/17/CC11-Hessian%E7%9F%A9%E9%98%B5/">预告</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="什么是Hessian矩阵？"><a href="#什么是Hessian矩阵？" class="headerlink" title="什么是Hessian矩阵？"></a>什么是Hessian矩阵？</h1><p>Hessian矩阵，又称为海森矩阵或黑塞矩阵，是由多元函数的二阶偏导数构成的方阵。它主要用于描述函数在某一点附近的局部曲率，即函数在该点附近的变化趋势。这一概念最早由德国数学家Ludwig Otto Hesse提出，是数学、特别是多元函数微分学中的重要工具。</p>
<p>对于一个二元函数 $f(x, y)$，其Hessian矩阵 $H$ 可以表示为：</p>
<script type="math/tex; mode=display">
H(f) = \begin{bmatrix}
\frac{\partial^2 f}{\partial x^2} & \frac{\partial^2 f}{\partial x \partial y} \\
\frac{\partial^2 f}{\partial y \partial x} & \frac{\partial^2 f}{\partial y^2}
\end{bmatrix}</script><p>对于一个 $n$ 元函数 $f(x_1, x_2, \ldots, x_n)$，其Hessian矩阵是一个 $n \times n$ 的矩阵，其中第 $i$ 行第 $j$ 列的元素是 $f$ 关于 $x_i$ 和 $x_j$ 的二阶偏导数：</p>
<script type="math/tex; mode=display">
H(f) = \begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1 \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} & \frac{\partial^2 f}{\partial x_2^2} & \cdots & \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} & \frac{\partial^2 f}{\partial x_n \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}</script><p>Hessian矩阵在优化问题中非常重要，因为它可以用来判断函数在某一点是否为极值点。具体来说：</p>
<ol>
<li>如果Hessian矩阵是正定的，那么函数在该点有局部最小值。</li>
<li>如果Hessian矩阵是负定的，那么函数在该点有局部最大值。</li>
<li>如果Hessian矩阵是不定的，那么函数在该点可能是一个鞍点。</li>
</ol>
<p>此外，Hessian矩阵还用于牛顿法等优化算法中，帮助找到函数的极值点。</p>
<h1 id="Hessian矩阵的通俗解释"><a href="#Hessian矩阵的通俗解释" class="headerlink" title="Hessian矩阵的通俗解释"></a>Hessian矩阵的通俗解释</h1><p>好的，让我们用一个更通俗易懂的方式来理解Hessian矩阵。</p>
<p>想象一下，你有一个三维空间中的山丘，这个山丘的形状由一个函数 $f(x, y)$ 来描述，其中 $x$ 和 $y$ 是水平方向的坐标，而 $f(x, y)$ 是山丘的高度。</p>
<p>现在，你想知道这个山丘在某个特定点的地形特征，比如它是不是最高峰或者最低谷。为了做到这一点，你可以观察这个点附近的斜率（一阶导数）和曲率（二阶导数）。Hessian矩阵就是帮助我们量化这种曲率的工具。</p>
<h3 id="1-一阶导数：斜率"><a href="#1-一阶导数：斜率" class="headerlink" title="1. 一阶导数：斜率"></a>1. 一阶导数：斜率</h3><p>一阶导数告诉我们山丘在任何方向上的斜率。如果斜率为正，意味着沿着那个方向走，山丘会上升；如果斜率为负，意味着会下降。</p>
<h3 id="2-二阶导数：曲率"><a href="#2-二阶导数：曲率" class="headerlink" title="2. 二阶导数：曲率"></a>2. 二阶导数：曲率</h3><p>二阶导数告诉我们山丘的曲率，也就是斜率变化的快慢。如果二阶导数为正，意味着山丘在那个方向上是向上弯曲的（凹形）；如果为负，意味着是向下弯曲的（凸形）。</p>
<h3 id="3-Hessian矩阵：曲率的矩阵"><a href="#3-Hessian矩阵：曲率的矩阵" class="headerlink" title="3. Hessian矩阵：曲率的矩阵"></a>3. Hessian矩阵：曲率的矩阵</h3><p>Hessian矩阵就是将所有这些二阶导数（曲率）放在一起，形成一个矩阵。对于一个二元函数，这个矩阵看起来像这样：</p>
<script type="math/tex; mode=display">
H(f) = \begin{bmatrix}
xx\text{方向的曲率} & xy\text{方向的曲率} \\
yx\text{方向的曲率} & yy\text{方向的曲率}
\end{bmatrix}</script><ul>
<li><strong>$xx$ 方向的曲率</strong>：告诉你在 $x$ 方向上，山丘的曲率如何变化。</li>
<li><strong>$yy$ 方向的曲率</strong>：告诉你在 $y$ 方向上，山丘的曲率如何变化。</li>
<li><strong>$xy$ 和 $yx$ 方向的曲率</strong>：告诉你在 $x$ 和 $y$ 方向上，山丘的曲率是如何相互影响的。</li>
</ul>
<h3 id="4-判断极值点"><a href="#4-判断极值点" class="headerlink" title="4. 判断极值点"></a>4. 判断极值点</h3><p>通过分析Hessian矩阵，我们可以判断山丘上的点是山峰、山谷还是鞍点：</p>
<ul>
<li>如果Hessian矩阵是正定的（所有特征值都为正），那么这个点是局部最低点（山谷）。</li>
<li>如果Hessian矩阵是负定的（所有特征值都为负），那么这个点是局部最高点（山峰）。</li>
<li>如果Hessian矩阵是不定的（有正有负的特征值），那么这个点是鞍点。</li>
</ul>
<p>这样，Hessian矩阵就帮助我们理解了函数在特定点的局部行为，就像我们通过观察山丘的地形来了解它的特征一样。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/12/17/CC11-Hessian%E7%9F%A9%E9%98%B5/" data-id="cm5m32i68000p6obq7je6c1kz" data-title="预告" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hessian%E7%9F%A9%E9%98%B5/" rel="tag">Hessian矩阵</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%BA%8C%E9%98%B6%E4%BC%98%E5%8C%96/" rel="tag">二阶优化</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/" rel="tag">微积分</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%A9%AC%E5%90%8C%E5%AD%A6/" rel="tag">马同学</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-CC12-傅里叶变换" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/29/CC12-%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/" class="article-date">
  <time class="dt-published" datetime="2024-10-28T16:00:00.000Z" itemprop="datePublished">2024-10-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/">微积分</a>►<a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/29/CC12-%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/">傅里叶变换：如何用一个公式读懂宇宙的语言？</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>在现代科学和工程的许多领域，信号和时间序列数据无处不在，从股市的波动到心电图的跳动，从音频的波形到无线通信的信号。理解和分析这些数据的关键在于傅里叶变换，这是一种强大的数学工具，它能够揭示隐藏在时间序列背后的频率成分。</p>
<p>傅里叶变换不仅仅是一个数学公式，它是一扇窗，让我们能够窥见信号的内在频率结构。</p>
<p>在这篇文章中，我们将深入探讨傅里叶变换的基本原理，以及它在信号处理和时序数据分析中的应用。</p>
<h1 id="什么是傅里叶变换？"><a href="#什么是傅里叶变换？" class="headerlink" title="什么是傅里叶变换？"></a>什么是傅里叶变换？</h1><p>在现实世界中，我们经常会遇到各种信号，比如声音、光、电信号等。这些信号可以被看作是随时间或空间变化的波形。</p>
<p>比如一段复杂的音乐，实际上是由许多不同频率和振幅的简单波形叠加而成的。这些简单波形可以是正弦波或余弦波。</p>
<p>傅里叶变换的作用就是将这些复杂的信号分解成若干个简单波形的组合。它告诉我们，一个复杂的信号可以由哪些不同频率的正弦波或余弦波组成，以及每个波的振幅和相位。</p>
<p>傅里叶变换的定义：<br>傅里叶变换是一种将时间域（信号随时间变化的情况）的信号转换到频率域（信号由哪些频率的波形组成）的数学工具。它在信号处理、图像处理、通信系统等领域有着广泛的应用。傅里叶变换的数学定义如下：</p>
<p>傅里叶变换是一种将时间域（或空间域）的信号转换到频率域的数学工具。它在信号处理、图像处理、通信系统等领域有着广泛的应用。傅里叶变换的数学定义如下：</p>
<p>对于一个连续时间函数 $f(t)$，其傅里叶变换 $F(\omega)$ 定义为：</p>
<script type="math/tex; mode=display">
F(\omega) = \int_{-\infty}^{\infty} f(t) e^{-j\omega t} \, dt</script><p>其中， $\omega$ 是角频率， $j$ 是虚数单位， $e^{-j\omega t}$ 是复指数函数。</p>
<p>对于一个离散时间序列 $f[n]$，其离散时间傅里叶变换（DTFT） $F(e^{j\omega})$ 定义为：</p>
<script type="math/tex; mode=display">
F(e^{j\omega}) = \sum_{n=-\infty}^{\infty} f[n] e^{-j\omega n}</script><p>对于一个离散时间序列 $f[n]$，其离散傅里叶变换（DFT） $F[k]$ 定义为：</p>
<script type="math/tex; mode=display">
F[k] = \sum_{n=0}^{N-1} f[n] e^{-j2\pi kn/N}</script><p>其中， $N$ 是序列的长度， $k$ 是频率索引。</p>
<p>傅里叶变换的逆变换可以将频率域的信号转换回时间域。对于连续时间函数，逆傅里叶变换定义为：</p>
<script type="math/tex; mode=display">
f(t) = \frac{1}{2\pi} \int_{-\infty}^{\infty} F(\omega) e^{j\omega t} \, d\omega</script><p>对于离散时间序列，逆离散时间傅里叶变换（IDTFT）定义为：</p>
<script type="math/tex; mode=display">
f[n] = \frac{1}{2\pi} \int_{-\pi}^{\pi} F(e^{j\omega}) e^{j\omega n} \, d\omega</script><p>对于离散时间序列，逆离散傅里叶变换（IDFT）定义为：</p>
<script type="math/tex; mode=display">
f[n] = \frac{1}{N} \sum_{k=0}^{N-1} F[k] e^{j2\pi kn/N}</script><p>傅里叶变换的这些定义和性质在信号处理和通信系统中扮演着重要的角色，帮助我们分析和设计系统。</p>
<h1 id="傅里叶变换的通俗解释"><a href="#傅里叶变换的通俗解释" class="headerlink" title="傅里叶变换的通俗解释"></a>傅里叶变换的通俗解释</h1><h3 id="故事：音乐与和声"><a href="#故事：音乐与和声" class="headerlink" title="故事：音乐与和声"></a>故事：音乐与和声</h3><p>想象一下，你正在听一首复杂的交响乐。这首曲子由许多不同的乐器组成，它们各自演奏着不同的音符。这些音符混合在一起，形成了美妙的音乐。现在，假设你想要单独听出每种乐器的声音，或者你想要分析这首曲子中有哪些音符。</p>
<h3 id="问题：混合与分离"><a href="#问题：混合与分离" class="headerlink" title="问题：混合与分离"></a>问题：混合与分离</h3><p>在音乐播放时，所有的音符都混合在一起，就像把许多颜色的颜料混在一起，很难分辨出单独的颜色。傅里叶变换就像是一个魔法工具，它可以帮助我们从混合的音乐中分离出单独的音符。</p>
<h3 id="原理：分解与重建"><a href="#原理：分解与重建" class="headerlink" title="原理：分解与重建"></a>原理：分解与重建</h3><ol>
<li><p><strong>分解</strong>：傅里叶变换的原理是，任何复杂的波形（比如音乐）都可以被分解成一系列简单的正弦波（就像单独的音符）。这些正弦波有不同的频率、振幅和相位。傅里叶变换就是找出这些正弦波的频率、振幅和相位的过程。</p>
</li>
<li><p><strong>重建</strong>：知道了这些正弦波的参数后，理论上我们可以重新构建出原来的复杂波形。这就像是有了颜料的配方，我们可以重新调配出原来的颜色。</p>
</li>
</ol>
<h3 id="比喻：超市结账"><a href="#比喻：超市结账" class="headerlink" title="比喻：超市结账"></a>比喻：超市结账</h3><p>想象一下超市结账的过程：顾客把各种商品（每种商品代表一个频率的正弦波）放在传送带上，收银员（傅里叶变换）快速地识别出每种商品，并计算出总价。这个过程就像是傅里叶变换，它识别出音乐中的每个音符，并计算出它们各自的贡献。</p>
<h1 id="傅里叶变换的应用"><a href="#傅里叶变换的应用" class="headerlink" title="傅里叶变换的应用"></a>傅里叶变换的应用</h1><h2 id="信号处理"><a href="#信号处理" class="headerlink" title="信号处理"></a>信号处理</h2><p>傅里叶变换在信号处理中的应用非常广泛，它帮助我们分析、处理和理解信号。以下是一些具体的应用实例：</p>
<ol>
<li>滤波器设计</li>
</ol>
<p>傅里叶变换可以将信号从时间域转换到频率域，这使得设计滤波器变得更加直观。通过滤波器，我们可以去除不需要的频率成分（如噪声），保留有用的信号。</p>
<ol>
<li>信号去噪</li>
</ol>
<p>在实际的信号采集过程中，信号往往会被噪声干扰。傅里叶变换可以将信号分解成不同频率的成分，然后我们可以设计滤波器去除噪声频率，从而净化信号。</p>
<ol>
<li>调制与解调</li>
</ol>
<p>在通信系统中，调制是将信息信号转换为适合传输的形式，而解调则是将接收到的信号还原为原始信息。傅里叶变换在这两个过程中都扮演着重要角色，帮助我们分析和处理信号的频率成分。</p>
<ol>
<li>语音识别</li>
</ol>
<p>在语音识别技术中，傅里叶变换可以分析语音信号的频率成分，提取特征，用于语音的识别和处理。</p>
<ol>
<li>图像处理</li>
</ol>
<p>傅里叶变换在图像处理中用于分析图像的频率成分，实现图像的滤波、增强、压缩和复原等功能。</p>
<h2 id="时间序列分析"><a href="#时间序列分析" class="headerlink" title="时间序列分析"></a>时间序列分析</h2><p>傅里叶变换在时间序列分析中的应用非常广泛，以下是一些关键的应用领域：</p>
<ol>
<li>趋势识别与季节性分析</li>
</ol>
<p>傅里叶变换能够帮助识别时间序列中的长期趋势和季节性模式。低频分量通常对应于趋势，而高频分量对应于短期波动或季节性变化。</p>
<ol>
<li>异常值检测</li>
</ol>
<p>在时间序列中，异常值可能表现为高频分量或相位偏移。傅里叶变换可以帮助检测这些异常值，从而在数据预处理中进行异常值的识别和处理。</p>
<ol>
<li>时间序列预测</li>
</ol>
<p>傅里叶变换可以用于时间序列预测。通过将时间序列分解为其频率分量，我们可以识别和利用时间序列中的模式来进行预测。这种方法特别适用于具有周期性特征的时间序列数据。</p>
<ol>
<li>周期性分析</li>
</ol>
<p>傅里叶变换可以用来分析时间序列的周期性。通过观察频域中的主要频率分量，我们可以识别时间序列的主要周期。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/10/29/CC12-%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/" data-id="cm5m32i67000m6obqetdy8vfl" data-title="傅里叶变换：如何用一个公式读懂宇宙的语言？" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/" rel="tag">傅里叶变换</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/" rel="tag">微积分</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%97%B6%E5%BA%8F%E5%88%86%E6%9E%90/" rel="tag">时序分析</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%A9%AC%E5%90%8C%E5%AD%A6/" rel="tag">马同学</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-CC10-雅可比矩阵" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/24/CC10-%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5/" class="article-date">
  <time class="dt-published" datetime="2024-10-23T16:00:00.000Z" itemprop="datePublished">2024-10-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/">微积分</a>►<a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/24/CC10-%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5/">预告篇</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="什么是雅可比矩阵？"><a href="#什么是雅可比矩阵？" class="headerlink" title="什么是雅可比矩阵？"></a>什么是雅可比矩阵？</h1><p>雅可比矩阵，听起来挺高大上的，但其实它就是一个表格，用来记录一个函数里每个变量是怎么影响结果的。<br>比如，你有一个函数，输入是火候和调料量，输出是菜肴的味道。雅可比矩阵就会告诉你，火候变一点，味道会怎么变；调料量变一点，味道又会怎么变。</p>
<p>在单变量微积分中，我们学习了导数，它告诉我们函数在某一点的变化率。但在多变量微积分中，情况就复杂多了。雅可比矩阵就是用来描述多变量函数变化率的工具。</p>
<p>雅可比矩阵的重要性在于它体现了一个可微方程与给出点的最优线性逼近。因此，雅可比矩阵类似于多元函数的导数。</p>
<p>在线性代数中，雅可比矩阵是函数的一阶偏导数以一定方式排列成的矩阵，其行列式称为雅可比行列式。</p>
<h2 id="数学定义"><a href="#数学定义" class="headerlink" title="数学定义"></a>数学定义</h2><p>假设我们有一个从 $\mathbb{R}^n$ 到 $\mathbb{R}^m$ 的函数 $f$，可以表示为 $f(x_1, x_2, \ldots, x_n)$$ = (f_1(x_1, x_2, \ldots, x_n),$ $ f_2(x_1, x_2, \ldots, x_n),$ $ \ldots, f_m(x_1, x_2, \ldots, x_n))$。</p>
<p>那么，雅可比矩阵 $J$ 就是这个函数所有偏导数的矩阵表示，定义如下：</p>
<script type="math/tex; mode=display">
J = \begin{bmatrix}
\frac{\partial f_1}{\partial x_1} & \frac{\partial f_1}{\partial x_2} & \cdots & \frac{\partial f_1}{\partial x_n} \\
\frac{\partial f_2}{\partial x_1} & \frac{\partial f_2}{\partial x_2} & \cdots & \frac{\partial f_2}{\partial x_n} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial f_m}{\partial x_1} & \frac{\partial f_m}{\partial x_2} & \cdots & \frac{\partial f_m}{\partial x_n}
\end{bmatrix}</script><p>雅可比矩阵的每一行对应于函数 $f$ 的一个分量函数 $f_i$ 对所有变量 $x_j$ 的偏导数，而每一列则对应于所有分量函数对一个特定变量 $x_j$ 的偏导数。</p>
<h2 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h2><ol>
<li><p><strong>维度</strong>：雅可比矩阵的维度是 $m \times n$，其中 $m$ 是函数 $f$ 的输出维度，$n$ 是输入维度。</p>
</li>
<li><p><strong>线性变换</strong>：雅可比矩阵可以被看作是函数 $f$ 在某一点的线性近似。它描述了函数在该点的局部线性行为。</p>
</li>
<li><p><strong>链式法则</strong>：如果 $f$ 是一个复合函数，即 $f = g \circ h$，那么 $f$ 的雅可比矩阵可以通过 $g$ 和 $h$ 的雅可比矩阵的乘积来计算，即 $J_f = J_g \cdot J_h$。</p>
</li>
<li><p><strong>可逆性</strong>：如果 $f$ 是一个双射函数（即一一对应），那么它的雅可比矩阵在某些条件下是可逆的。雅可比矩阵的可逆性与函数的局部可逆性有关。</p>
</li>
<li><p><strong>行列式</strong>：雅可比矩阵的行列式，称为雅可比行列式，它描述了函数 $f$ 在某一点的局部伸缩因子。在变量变换中，雅可比行列式用于调整积分的体积元素。</p>
</li>
<li><p><strong>对称性</strong>：如果 $f$ 的所有二阶偏导数都存在且连续，那么雅可比矩阵的转置等于 $f$ 的梯度向量。</p>
</li>
<li><p><strong>反对称性</strong>：雅可比矩阵具有反对称性。这意味着对于一个n维雅可比矩阵，如果将它转置，那么它的值会变为相反数。</p>
</li>
<li><p><strong>投影性质</strong>：雅可比矩阵具有投影性质。投影性质指的是将一个矩阵的行或列投影到另一个矩阵中，得到一个新的矩阵。对于一个n维雅可比矩阵，它的投影是一个n维单位矩阵。</p>
</li>
</ol>
<p>通过雅可比矩阵，我们可以了解函数在某一点的局部线性行为，以及函数在变量变换中的伸缩因子。</p>
<h1 id="雅可比矩阵的直观理解"><a href="#雅可比矩阵的直观理解" class="headerlink" title="雅可比矩阵的直观理解"></a>雅可比矩阵的直观理解</h1><p>想象一下，你正在玩一个视频游戏，游戏里的角色可以向左、向右、向前、向后移动。每个动作都会让角色在游戏世界中的位置发生变化。现在，我们把这些动作看作是输入（就像我们控制游戏手柄的指令），角色的位置变化看作是输出。</p>
<p>如果我们想要了解，当我们按下游戏手柄的某个按钮时，角色会移动多少距离，我们就需要一个“移动手册”来告诉我们每个动作对应的移动量。这个“移动手册”就像是雅可比矩阵。</p>
<p>具体来说，雅可比矩阵是一个表格，它告诉我们当我们改变输入（游戏手柄的指令）时，输出（角色的位置）会如何变化。在这个游戏中，雅可比矩阵可能看起来是这样的：</p>
<script type="math/tex; mode=display">
J = \begin{bmatrix}
\frac{\partial x}{\partial \text{左键}} & \frac{\partial x}{\partial \text{右键}} \\
\frac{\partial y}{\partial \text{前键}} & \frac{\partial y}{\partial \text{后键}}
\end{bmatrix}</script><p>这里，$\frac{\partial x}{\partial \text{左键}}$ 表示按下左键时角色在x轴上移动的距离，$\frac{\partial y}{\partial \text{前键}}$ 表示按下前键时角色在y轴上移动的距离。</p>
<p>在现实世界中，雅可比矩阵的应用要复杂得多，但它的基本思想是一样的：它是一个“手册”，告诉我们当输入变化时输出会如何变化。在数学中，这个“输出”可能是一个复杂的函数，而“输入”可能是多个变量，但雅可比矩阵的核心概念是相同的：它是一个描述输入和输出之间关系的矩阵。</p>
<h1 id="雅可比矩阵的应用"><a href="#雅可比矩阵的应用" class="headerlink" title="雅可比矩阵的应用"></a>雅可比矩阵的应用</h1><h2 id="微积分中的应用"><a href="#微积分中的应用" class="headerlink" title="微积分中的应用"></a>微积分中的应用</h2><p>雅可比矩阵在微积分中的应用非常广泛，它提供了一种描述多变量函数局部线性行为的方法。以下是一些主要的应用：</p>
<ol>
<li><p><strong>变量变换</strong>：<br>在多变量积分中，雅可比矩阵用于变量变换。当我们将一个积分从一个坐标系变换到另一个坐标系时，雅可比行列式（雅可比矩阵的行列式）作为变换的伸缩因子，确保积分的值保持不变。例如，在从笛卡尔坐标系到极坐标系的变换中，雅可比行列式是 $r$，因此在极坐标系中的面积元素是 $r \, dr \, d\theta$。</p>
</li>
<li><p><strong>线性近似</strong>：<br>雅可比矩阵可以用来对多变量函数进行线性近似。在某一点的雅可比矩阵给出了函数在该点的局部线性行为，这在函数的泰勒展开中非常有用。线性近似可以简化复杂函数的分析，特别是在函数的非线性行为不明显时。</p>
</li>
<li><p><strong>链式法则</strong>：<br>在多变量微积分中，链式法则用于计算复合函数的导数。如果 $y = f(g(x))$，那么 $y$ 对 $x$ 的导数可以通过 $f$ 和 $g$ 的雅可比矩阵的乘积来计算。这在处理多变量函数的复合时非常有用。</p>
</li>
<li><p><strong>优化问题</strong>：<br>在优化问题中，雅可比矩阵用于找到函数的临界点。通过将雅可比矩阵设为零，我们可以找到函数的局部极值点。此外，雅可比矩阵的行列式（海森矩阵）可以用来确定这些临界点的性质（即它们是极大值、极小值还是鞍点）。</p>
</li>
<li><p><strong>微分方程</strong>：<br>在微分方程中，雅可比矩阵用于分析系统的稳定性。对于一个非线性系统，通过在平衡点处计算雅可比矩阵，我们可以线性化系统并分析其稳定性。如果雅可比矩阵的所有特征值的实部都是负的，那么平衡点是稳定的。</p>
</li>
</ol>
<h2 id="机器学习中的应用"><a href="#机器学习中的应用" class="headerlink" title="机器学习中的应用"></a>机器学习中的应用</h2><p>雅可比矩阵在优化算法中的应用主要体现在以下几个方面：</p>
<ol>
<li><p><strong>梯度下降法</strong>：<br>梯度下降法是一种常用的优化算法，用于最小化目标函数。在机器学习中，我们经常需要最小化一个损失函数来优化模型参数。雅可比矩阵在这里的作用是计算损失函数对模型参数的梯度。梯度是损失函数在参数空间中的导数，它指示了损失函数增长最快的方向。雅可比矩阵包含了这些梯度信息，从而指导参数更新的方向和步长。</p>
</li>
<li><p><strong>优化问题的步长计算</strong>：<br>在一些优化算法中，雅可比矩阵不仅用于计算梯度，还用于确定步长。例如，在牛顿法等二阶优化算法中，除了需要梯度信息外，还需要二阶导数信息（即海森矩阵），雅可比矩阵在这里可以提供梯度信息，辅助计算步长，以更有效地逼近最优解。</p>
</li>
<li><p><strong>反向传播</strong>：<br>在深度学习中，雅可比矩阵与反向传播算法紧密相关。反向传播算法通过计算损失函数对网络参数的梯度来训练神经网络。雅可比矩阵在这里用于计算这些梯度，从而更新网络权重，优化网络性能。</p>
</li>
<li><p><strong>局部线性近似</strong>：<br>雅可比矩阵蕴含着映射的局部线性近似特征（信息）。在深度学习中，如果因变量也变成多个值（即向量），我们对每个因变量在参数点都求一个方向导数，这些方向导数构成一个矩阵，即雅可比矩阵。这个矩阵的每一行是原函数的分量的梯度。</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/10/24/CC10-%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5/" data-id="cm5m32i66000i6obqhtyfbonc" data-title="预告篇" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%9A%E5%8F%98%E9%87%8F%E5%87%BD%E6%95%B0/" rel="tag">多变量函数</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/" rel="tag">微积分</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5/" rel="tag">雅可比矩阵</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%A9%AC%E5%90%8C%E5%AD%A6/" rel="tag">马同学</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-CC09-拉格朗日乘数法" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/22/CC09-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0%E6%B3%95/" class="article-date">
  <time class="dt-published" datetime="2024-10-21T16:00:00.000Z" itemprop="datePublished">2024-10-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/">微积分</a>►<a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/22/CC09-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0%E6%B3%95/">预告</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>你是否曾在面对复杂的优化问题时感到束手无策？是否在寻找一种方法，能够在满足一系列约束的同时，找到函数的最大值或最小值？<br>如果你的答案是肯定的，那么这篇文章正是为你准备的。我们将从一个震撼的事实开始：拉格朗日乘数法不仅在数学领域中占据着举足轻重的地位，而且在机器学习的实际应用中，它也扮演着不可或缺的角色。</p>
<p>想象一下，你正站在一个多维空间的山顶上，四周是连绵起伏的山丘和山谷，你的目标是找到最低的山谷——也就是函数的最小值。但是，你不能随意走动，必须沿着某些特定的路径——这就是约束条件。拉格朗日乘数法就是你的指南针，它将引导你沿着这些路径，找到那些可能的最低点。</p>
<p>在这篇文章中，我将带你一起旅行，从拉格朗日乘数法的基本概念出发，逐步深入到它在机器学习中的高级应用。</p>
<h3 id="什么是拉格朗日乘数法"><a href="#什么是拉格朗日乘数法" class="headerlink" title="什么是拉格朗日乘数法"></a>什么是拉格朗日乘数法</h3><p>拉格朗日乘数法，以数学家约瑟夫·路易斯·拉格朗日命名，是一种寻找变量受一个或多个条件所限制的多元函数的极值的方法。</p>
<p>简单来说，它可以将一个有n个变量与k个约束条件的最优化问题转换为一个有n+k个变量的方程组的极值问题，其变量不受任何约束。这种方法引入了一种新的标量未知数，即拉格朗日乘数，它是约束方程的梯度（gradient）的线性组合里每个向量的系数。</p>
<h4 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h4><p>假设你有一个函数 $f(x,y)$，你想要在约束条件 $g(x,y)=c$ 下找到这个函数的最大值或最小值。拉格朗日乘数法通过引入一个新的变量 $\lambda$（拉格朗日乘数），将约束条件纳入到优化问题中。</p>
<p>1.<strong>构造拉格朗日函数</strong>：定义拉格朗日函数 $L(x,y,\lambda)$ 为：</p>
<script type="math/tex; mode=display">

L(x,y,\lambda)=f(x,y)-\lambda(g(x,y)-c)</script><p>其中，$\lambda$ 是拉格朗日乘数。</p>
<p>2.<strong>求偏导数</strong>：计算 $L$ 对 $x$，$y$，和 $\lambda$ 的偏导数，并令它们等于零：</p>
<script type="math/tex; mode=display">
\frac{\partial L}{\partial x}=0, \quad \frac{\partial L}{\partial y}=0, \quad \frac{\partial L}{\partial \lambda}=0</script><p>3.<strong>解方程组</strong>：解上述方程组，找到 $x$，$y$，和 $\lambda$ 的值。</p>
<p>4.<strong>验证解</strong>：通过二阶导数检验或其他方法验证找到的解是极大值、极小值还是鞍点。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/10/22/CC09-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0%E6%B3%95/" data-id="cm5m32i66000l6obq5rzk897m" data-title="预告" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/" rel="tag">微积分</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0%E6%B3%95/" rel="tag">拉格朗日乘数法</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96/" rel="tag">约束优化</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%A9%AC%E5%90%8C%E5%AD%A6/" rel="tag">马同学</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-CC08-泰勒公式" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/19/CC08-%E6%B3%B0%E5%8B%92%E5%85%AC%E5%BC%8F/" class="article-date">
  <time class="dt-published" datetime="2024-10-18T16:00:00.000Z" itemprop="datePublished">2024-10-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/">微积分</a>►<a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/19/CC08-%E6%B3%B0%E5%8B%92%E5%85%AC%E5%BC%8F/">预告篇</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p><strong>“想象一下，你能够用一个简单的公式，精确地描绘出复杂函数的全貌。这不是魔法，这是泰勒公式的魅力。”</strong></p>
<p>你是否曾好奇，一个简单的数学公式如何能够预测复杂的函数行为，甚至在人工智能的心脏——机器学习中扮演关键角色？泰勒公式，这个看似简单的工具，实际上是一个强大的预测引擎，它能够能够将复杂的函数简化为几个简单的项。并对它们的行为做出精确的预测。</p>
<p><strong>准备好了吗？让我们一起探索泰勒公式的奥秘，看看它是如何在微积分和机器学习中施展魔法的。</strong></p>
<h1 id="什么是泰勒公式？"><a href="#什么是泰勒公式？" class="headerlink" title="什么是泰勒公式？"></a>什么是泰勒公式？</h1><p>泰勒公式是由英国数学家布鲁克·泰勒（Brook Taylor, 1685-1732）在1712年首次提出的。它是一个用于近似表达复杂函数的数学公式。简单来说，泰勒公式利用函数在某一点的各阶导数值，构建一个多项式近似函数，从而求得该点附近的值。</p>
<p>泰勒公式的核心思想在于，如果一个函数足够平滑，且在已知其在某一点的各阶导数值的情况下，我们可以利用这些导数值作为系数，构建一个多项式函数来逼近原函数。这个多项式函数在原函数图像上的某一点展开，随着项数的增加，逼近的精度也会提高。</p>
<h1 id="泰勒公式的推导"><a href="#泰勒公式的推导" class="headerlink" title="泰勒公式的推导"></a>泰勒公式的推导</h1><p>首先，想象一下，你有一个非常复杂的函数，比如一座山的地形图，你想要在地图上的某一点附近画一条曲线，这条曲线能够尽可能地贴近这座山的实际形状。泰勒公式就是帮你画这条曲线的工具。</p>
<p>假设你站在山脚下（我们称之为点a），你想知道山在这一点附近的形状。你可以通过测量山的坡度（也就是函数的导数）来了解这一点。如果你只知道山在这一点的坡度（一阶导数），那么你可以用一条直线来近似山的形状。</p>
<p>但是，如果你还知道山的曲率（二阶导数），你就可以用一个抛物线来更好地近似山的形状。如果你知道更多的信息，比如山的凹凸性（三阶导数），你就可以用一个三次多项式来近似，以此类推。</p>
<p>每次你增加一个导数的信息，就可以在多项式中增加一个项，这样你的近似就会越来越精确。这个多项式就是泰勒多项式。</p>
<p>但是，不管你知道多少导数的信息，你的多项式都不可能完全等于原来的复杂函数，总会有一些误差。泰勒公式中的余项就是用来描述这个误差的。</p>
<p>用数学语言表达则是：</p>
<p>【泰勒公式的定义】</p>
<p>对于一个在点 $a$ 处具有所有阶导数的函数 $f(x)$，泰勒公式可以表示为：</p>
<script type="math/tex; mode=display">f(x)=f(a)+f'(a)(x-a)+\frac{f''(a)}{2!}(x-a)^2+\frac{f'''(a)}{3!}(x-a)^3+\cdots+\frac{f^{(n)}(a)}{n!}(x-a)^n+R_n(x)</script><p>其中，$R_n(x)$ 是余项，表示泰勒多项式与函数 $f(x)$ 之间的误差。</p>
<blockquote>
<p>在泰勒公式中若取$x_0=0$，则有<strong>麦克劳林公式</strong>：<br>$f(x)=f(0)+f’(0)x+\frac{f’’(0)}{2!}x^2<script type="math/tex">+\cdots+\frac{f^{(n)}(0)}{n!}x^n</script>+\frac{f^{(n+1)}(\theta x)}{(n+1)!}x^{n+1}\quad(0&lt;\theta&lt;1)$.<br>近似可得：$f(x)\approx f(0)+f’(0)x<script type="math/tex">+\frac{f''(0)}{2!}x^2+\cdots</script>+\frac{f^{(n)}(0)}{n!}x^n$.</p>
</blockquote>
<p>泰勒展开（Taylor expansion）是微积分中一个非常重要的概念，它描述了如何使用多项式来近似一个光滑函数。具体来说，泰勒展开允许我们在一个点附近用多项式来近似一个函数，这个点通常是函数的极值点或者是一个方便计算的点。</p>
<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>对于一个在某点 $a$ 附近具有无穷阶导数的函数 $f(x)$，其泰勒展开式（也称为麦克劳林展开式，如果 $a = 0$）可以表示为：</p>
<script type="math/tex; mode=display">

f(x) = f(a) + f'(a)(x-a) + \frac{f''(a)}{2!}(x-a)^2 + \frac{f'''(a)}{3!}(x-a)^3 + \cdots + \frac{f^{(n)}(a)}{n!}(x-a)^n + R_n(x)</script><p>其中，$f^{(n)}(a)$ 表示函数 $f$ 在 $a$ 处的第 $n$ 阶导数，$n!$ 是 $n$ 的阶乘，$R_n(x)$ 是余项，表示用 $n$ 阶多项式近似 $f(x)$ 时的误差。</p>
<h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><ol>
<li><p><strong>近似计算</strong>：泰勒展开可以将复杂的函数转化为多项式，便于计算和分析。在实际应用中，我们通常只取泰勒级数的前几项，因为随着项数的增加，计算的复杂度也会增加。</p>
</li>
<li><p><strong>误差估计</strong>：通过余项 ( R_n(x) )，我们可以估计近似的误差，这对于数值分析和算法的稳定性分析非常重要。</p>
</li>
<li><p><strong>函数的性质分析</strong>：泰勒展开可以帮助我们了解函数在某个点附近的行为，比如它的凹凸性、极值等。</p>
</li>
<li><p><strong>微分方程的解法</strong>：在求解微分方程时，泰勒展开可以用来构造级数解。</p>
</li>
<li><p><strong>优化算法</strong>：在数值优化中，泰勒展开可以用来构造函数的局部近似，进而用于寻找极值点。</p>
</li>
<li><p><strong>物理学和工程学中的应用</strong>：在物理学和工程学中，泰勒展开被用来近似复杂的物理过程和工程问题，比如在力学、电磁学、量子力学等领域。</p>
</li>
</ol>
<p>泰勒展开是连接函数局部性质和全局性质的桥梁，它在数学分析、物理学、工程学以及其他科学领域都有着广泛的应用。</p>
<h3 id="2-推导过程"><a href="#2-推导过程" class="headerlink" title="2.推导过程"></a>2.推导过程</h3><h4 id="a-拉格朗日形式的余项"><a href="#a-拉格朗日形式的余项" class="headerlink" title="a.拉格朗日形式的余项"></a>a.拉格朗日形式的余项</h4><p>首先，我们考虑函数 $f(x)$ 在区间 $[a,x]$ 上的拉格朗日中值定理（Lagrange’sMeanValueTheorem）：</p>
<script type="math/tex; mode=display">f(x)-f(a)=f'(\xi)(x-a)</script><p>其中，$\xi$ 是 $a$ 和 $x$ 之间的某个点。</p>
<h4 id="b-两次应用中值定理"><a href="#b-两次应用中值定理" class="headerlink" title="b.两次应用中值定理"></a>b.两次应用中值定理</h4><p>我们可以对 $f’(\xi)$ 再次应用中值定理：</p>
<script type="math/tex; mode=display">f'(\xi)=f'(a)+f''(\eta)(\xi-a)</script><p>其中，$\eta$ 是 $a$ 和 $\xi$ 之间的某个点。</p>
<p>将 $f’(\xi)$ 代入第一步的等式中，我们得到：</p>
<script type="math/tex; mode=display">f(x)-f(a)=[f'(a)+f''(\eta)(\xi-a)](x-a)</script><h4 id="c-推广到高阶导数"><a href="#c-推广到高阶导数" class="headerlink" title="c.推广到高阶导数"></a>c.推广到高阶导数</h4><p>我们可以继续这个过程，对 $f’’(\eta)$ 应用中值定理，然后是 $f’’’$，以此类推，直到 $n$ 阶导数。每次应用中值定理，我们都会引入一个新的$\xi$值，这些值都位于$a$和$x$之间。</p>
<h4 id="d-引入余项"><a href="#d-引入余项" class="headerlink" title="d.引入余项"></a>d.引入余项</h4><p>在 $n$ 次应用中值定理后，我们得到：</p>
<script type="math/tex; mode=display">f(x)=f(a)+f'(a)(x-a)+\frac{f''(a)}{2!}(x-a)^2+\cdots+\frac{f^{(n)}(a)}{n!}(x-a)^n+R_n(x)</script><p>其中，余项 $R_n(x)$ 可以表示为：</p>
<script type="math/tex; mode=display">R_n(x)=\frac{f^{(n+1)}(\xi_n)}{(n+1)!}(x-a)^{n+1}</script><p>这里的 $\xi_n$ 是 $a$ 和 $x$ 之间的某个点，取决于 $x$。</p>
<h3 id="3-结论"><a href="#3-结论" class="headerlink" title="3.结论"></a>3.结论</h3><p>泰勒公式提供了一种使用函数在某一点的导数信息来近似整个函数的方法。余项 $R_n(x)$ 描述了这种近似的误差，随着 $n$ 的增加，这个误差通常会减小，近似也变得更加精确。</p>
<p>这个推导过程展示了泰勒公式的基本原理，即通过局部的导数信息来构建对函数的全局近似。</p>
<h3 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h3><p>泰勒公式就像是用乐高积木搭建一个模型来近似一个复杂的物体。你拥有的积木块（导数信息）越多，你的模型就能越精确地反映物体的形状。但是，总会有一些细微的地方是积木无法完全复制的，这就是余项R_n(x)的作用，它告诉我们模型和真实物体之间的差距有多大。</p>
<p>希望这样的解释能让你更容易理解泰勒公式的推导过程！</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/10/19/CC08-%E6%B3%B0%E5%8B%92%E5%85%AC%E5%BC%8F/" data-id="cm5m32i65000h6obq2v7bbswl" data-title="预告篇" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/" rel="tag">微积分</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%A8%A1%E5%9E%8B%E7%AE%80%E5%8C%96/" rel="tag">模型简化</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B3%B0%E5%8B%92%E5%85%AC%E5%BC%8F/" rel="tag">泰勒公式</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%A9%AC%E5%90%8C%E5%AD%A6/" rel="tag">马同学</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-CC07-积分" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/17/CC07-%E7%A7%AF%E5%88%86/" class="article-date">
  <time class="dt-published" datetime="2024-10-16T16:00:00.000Z" itemprop="datePublished">2024-10-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/">微积分</a>►<a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/17/CC07-%E7%A7%AF%E5%88%86/">预告</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/10/17/CC07-%E7%A7%AF%E5%88%86/" data-id="cm5m32i64000e6obq0oyx485v" data-title="预告" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/" rel="tag">微积分</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B/" rel="tag">概率模型</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%A7%AF%E5%88%86/" rel="tag">积分</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%A9%AC%E5%90%8C%E5%AD%A6/" rel="tag">马同学</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-CC06-微分" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/15/CC06-%E5%BE%AE%E5%88%86/" class="article-date">
  <time class="dt-published" datetime="2024-10-14T16:00:00.000Z" itemprop="datePublished">2024-10-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/">微积分</a>►<a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/15/CC06-%E5%BE%AE%E5%88%86/">预告</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>在数学中，微分是描述变化和运动的强大工具。</p>
<p>它不仅在物理学中描述速度和加速度，在经济学中分析边际成本和收益，也在工程学中优化设计。</p>
<p>今天，我们就来聊聊微分的概念，看看它是如何帮助我们理解世界的。</p>
<h2 id="一、微分的由来"><a href="#一、微分的由来" class="headerlink" title="一、微分的由来"></a>一、微分的由来</h2><p><strong>微分，从古至今的智慧结晶</strong>。微分的概念并非一蹴而就，它的起源可以追溯到古代。在中国古代，庄子提出了极限思想，刘徽的割圆术也体现了积分思想的雏形。在西方，古希腊数学家如阿基米德使用的方法也类似于微积分中的极限概念。</p>
<p>在平面几何中，我们可以根据公式很轻松的计算出三角形、矩形、梯形等由直线围成的图像面积，以及圆、椭圆、扇形等特殊曲线所围成的图形面积。<br>![[Pasted image 20241026133001.png]]<br>但是，如果需要计算一个由曲线$y=f(x)$，与直线$x=a$和直线$x=b$所围成的图形面积，如上图所示，这种图形称为<em>曲边梯形</em>。我们可以尝试通过一些能轻松求出面积的图形来替代曲线图形。例如，用矩形面积来代替曲边梯形面积，这种方法叫作<strong>以直代曲</strong>。<br>![[Pasted image 20241026133757.png]]<br>当我们将其中的 $\Delta x_i$ 这个橙色的矩形单独拿出来分析可知，该矩形与函数 $y=f(x)$ 有两个交点 $a, \ b$，过 $a, \ b$ 作一条割线 $l$ 。另外，矩形中轴线与函数 $y=f(x)$ 交点为 $c$，过 $c$ 作一条函数 $y=f(x)$ 的切线 $k$ 。</p>
<p>当 $\Delta x_i$ 无限小时， $a, \ b$ 将趋近于 $c$，则割线就会无限与其切线重合。那么，当 $\Delta x_i$ 小到一定程度（$a, \ b, \ c$ 三点重合），则割线会成为切线吗？</p>
<p>当然不会，从割线与切线的定义来说，割线有两个交点，而切线只有一个交点。本质上，$a, \ b, \ c$ 三点是不会重合的，只是无限小。</p>
<p>这时，就需要一个微小变化量。于是，数学家将 $\Delta x_i$ 定义为 $dx$ 为 $x$ 的<strong>微分</strong>，将 $\Delta y_i$ 定义为 $dy$ 为 $y$ 的<strong>微分</strong>（微分即微小的变化量）。并将 $\frac{dy}{dx}$ 定义为导数，也就是切线的斜率（即因变量微分与自变量微分之比为导数）。因此，导数又叫做微分的商。</p>
<h2 id="三、微分的定义"><a href="#三、微分的定义" class="headerlink" title="三、微分的定义"></a>三、微分的定义</h2><p><strong>微分，函数变化的线性描述</strong>。在现代数学中，微分被定义为函数在某一点的局部变化的线性描述。</p>
<p>设函数 $y=f(x)$ 在某个区间内有定义，$x_0$ 及 $x_0+\Delta x$ 在此区间内，如果函数值增量：</p>
<script type="math/tex; mode=display">\Delta y = f(x_0+\Delta x) - f(x_0)</script><p>可表示为：</p>
<script type="math/tex; mode=display">\Delta y = A\Delta x+o(\Delta x)</script><p>其中，$A$ 是不依赖于 $\Delta x$ 的常数，那么称函数 $y=f(x)$ 在 $x_0$ 点处是可微的，而 $A\Delta x$ 叫作函数 $y=f(x)$ 在 $x_0$ 点相应于自变量增量 $\Delta x$ 的微分，记作 $dy$，即：</p>
<script type="math/tex; mode=display">dy=A\Delta x</script><p>通常令 $dx=\Delta x$，所以微分又表示为 $dy=Adx$。<br>![[Pasted image 20241026151508.png]]</p>
<p><strong>上述定义中式子的解读：</strong></p>
<ul>
<li>$\Delta y = f(x_0+\Delta x) - f(x_0)$，这其实就是曲线的表达式。</li>
<li>$dy=A\Delta x$，这其实就是直线的表达式，也就是 $x_0$ 点的微分的表达式。</li>
<li>$\Delta y = A\Delta x+o(\Delta x)$，该式可改写为 $o(\Delta x)=\Delta y - A\Delta x$，所以该式说的是曲线和微分相差 $o(\Delta x)$。<br>所以，微分定义其实说的就是：<script type="math/tex; mode=display">若 \ 曲线 - 直线=o(\Delta x) \to 该直线就是曲线的微分</script></li>
</ul>
<p><strong>微分与导数紧密相关</strong>。对一元函数来说，可微与可导是完全等价的概念。可微的函数，其微分等于导数乘以自变量的微分，换句话说，函数的微分与自变量的微分之商等于该函数的导数。因此，导数也叫做微商。于是函数的微分又可记作 $dy=f’(x)dx$。</p>
<h2 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h2><p>微分是描述变化的数学语言。它告诉我们，即使是非常小的变化，也可以被测量和预测。</p>
<p>虽然，微分在机器学习中没有直接应用，但通过微分定义的导数在机器学习中却有广泛的应用，例如梯度下降、反向传播等。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/10/15/CC06-%E5%BE%AE%E5%88%86/" data-id="cm5m32i63000d6obqea26e4tu" data-title="预告" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E5%88%86/" rel="tag">微分</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/" rel="tag">微积分</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%A9%AC%E5%90%8C%E5%AD%A6/" rel="tag">马同学</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-CC05-链式法则" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/12/CC05-%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99/" class="article-date">
  <time class="dt-published" datetime="2024-10-11T16:00:00.000Z" itemprop="datePublished">2024-10-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/">微积分</a>►<a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/12/CC05-%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99/">预告</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>链式法则（Chain Rule）是微积分中的一个基本法则，用于求复合函数的导数。复合函数是由两个或多个函数组合而成的函数。链式法则指出，如果有一个函数 $y = f(g(x))$，那么 $y$ 关于 $x$ 的导数可以通过以下方式计算：</p>
<script type="math/tex; mode=display">
\frac{dy}{dx} = \frac{dy}{du} \cdot \frac{du}{dx}</script><p>其中，$u = g(x)$，$y = f(u)$。</p>
<p>链式法则的直观理解是：如果 $y$ 是 $u$ 的函数，而 $u$ 又是 $x$ 的函数，那么 $y$ 通过 $u$ 间接依赖于 $x$。因此，$y$ 关于 $x$ 的变化率可以通过 $y$ 关于 $u$ 的变化率乘以 $u$ 关于 $x$ 的变化率来得到。</p>
<p>链式法则在多变量微积分中也有相应的形式，用于求偏导数。对于函数 $z = f(x, y)$，其中 $x = g(t)$ 和 $y = h(t)$，链式法则可以表示为：</p>
<script type="math/tex; mode=display">
\frac{dz}{dt} = \frac{\partial z}{\partial x} \cdot \frac{dx}{dt} + \frac{\partial z}{\partial y} \cdot \frac{dy}{dt}</script><p>链式法则在机器学习、深度学习、物理、工程等领域有广泛的应用，特别是在反向传播算法中，链式法则用于计算梯度，从而更新模型的参数。</p>
<p>好的，让我们用一个简单的例子来解释链式法则。</p>
<p>想象一下，你正在玩一个游戏，游戏中有一个按钮，每次按下按钮，都会触发一系列动作。比如，按下按钮后，一个球会从斜坡上滚下来，然后撞到一个铃铛，最后铃铛响了。</p>
<p>现在，如果你想知道每次按下按钮时铃铛响的音量变化，这就需要用到链式法则。因为铃铛的响声不仅取决于球撞到铃铛的力度，还取决于球从斜坡上滚下来的速度。而球的速度又取决于斜坡的倾斜角度。</p>
<p>所以，如果你想知道按下按钮对铃铛响声的影响，你就需要：</p>
<ol>
<li>先看斜坡倾斜角度的变化（这就像是内部函数，比如 $g(x)$）。</li>
<li>然后看这个角度变化如何影响球的速度（这就像是内部函数的导数，$g’(x)$）。</li>
<li>接着看球的速度如何影响球撞到铃铛的力度（这就像是外部函数，比如 $f(u)$，其中 $u$ 是球的速度）。</li>
<li>最后看这个力度如何影响铃铛的响声（这就像是外部函数的导数，$f’(u)$）。</li>
</ol>
<p>链式法则告诉我们，要找到按下按钮对铃铛响声的总影响，你需要把这两个影响相乘：球的速度变化对力度的影响（$f’(u)$）乘以斜坡倾斜角度变化对球速度的影响（$g’(x)$）。这样，你就可以得到按下按钮对铃铛响声的总影响，即 $f’(g(x)) \cdot g’(x)$。</p>
<p>简单来说，链式法则就是帮你理解一个动作（比如按下按钮）是如何通过一系列中间步骤（比如球滚下斜坡，撞到铃铛）影响到最终结果（铃铛响声）的。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/10/12/CC05-%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99/" data-id="cm5m32i62000a6obq8oo8e9g0" data-title="预告" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/" rel="tag">微积分</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">神经网络</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99/" rel="tag">链式法则</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%A9%AC%E5%90%8C%E5%AD%A6/" rel="tag">马同学</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-CC04-偏导数" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/10/CC04-%E5%81%8F%E5%AF%BC%E6%95%B0/" class="article-date">
  <time class="dt-published" datetime="2024-10-09T16:00:00.000Z" itemprop="datePublished">2024-10-10</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/">微积分</a>►<a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/10/10/CC04-%E5%81%8F%E5%AF%BC%E6%95%B0/">预告</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>大家好，今天我们来聊聊一个听起来有点高深，但实际上在现代科技中无处不在的数学概念——偏导数。它不仅是微积分的精髓，也是机器学习的核心。让我们一起探索偏导数的奥秘吧！</p>
<h2 id="微积分中的偏导数"><a href="#微积分中的偏导数" class="headerlink" title="微积分中的偏导数"></a>微积分中的偏导数</h2><p>首先，让我们回到基础。偏导数是多变量函数的导数，它描述了函数在某个方向上的变化率。想象一下，你有一座三维的山，偏导数就是告诉你在任何给定方向上，这座山的坡度有多大。</p>
<p>对于一个函数 f(x,y)，我们可以计算它关于 x 和 y 的偏导数：</p>
<ul>
<li><strong>关于 x 的偏导数</strong>：∂f∂x∂x∂f​，表示在 yy 保持不变时，xx 的变化如何影响函数值。</li>
<li><strong>关于 y 的偏导数</strong>：∂f∂y∂y∂f​，表示在 xx 保持不变时，yy 的变化如何影响函数值。</li>
</ul>
<p>数学上，偏导数可以通过极限来定义，这涉及到无穷小的变化和比率的概念。</p>
<p>梯度的定义</p>
<h2 id="机器学习中的偏导数"><a href="#机器学习中的偏导数" class="headerlink" title="机器学习中的偏导数"></a>机器学习中的偏导数</h2><p>机器学习是人工智能领域的一个重要分支，它旨在让计算机从数据中学习，以便在未知情况下做出决策。<br>在机器学习中，优化算法是一个关键的组件，它们通常涉及到最小化或最大化一个函数，以找到一个最佳的模型参数。这些优化算法通常依赖于计算函数梯度的能力，以便在梯度下降的方向上更新参数。</p>
<p>梯度下降的核心在于迭代更新参数。给定一个参数 $\theta_j$，通过以下公式进行更新：</p>
<script type="math/tex; mode=display">\theta _j: = \theta_j-\alpha \frac{\partial J(\theta)}{\partial \theta_j}</script><p>其中，$\alpha$ 是学习率，一个超参数，它控制我们朝梯度方向（即损失函数减少最快的方向）前进的步长。</p>
<p>以线性回归为例，我们的损失函数 $J(\theta)$ 可以表示为：</p>
<script type="math/tex; mode=display">J(\theta)=\frac{1}{2}\sum^m_{i=1}(h_{\theta}(x^{(i)}-y^{(i)})^2)</script><p>其中，$h_{\theta}(x)=\theta^Tx$ 是我们的假设函数，为了找到最小化损失函数的参数 $\theta$，我们需要计算 $J(\theta)$ 对每个 $\theta_j$ 的偏导数，并使用梯度下降的迭代公式进行更新。</p>
<p>偏导数在梯度下降算法中的作用是提供损失函数在每个参数方向上的变化率，这些信息被用来更新参数，以最小化损失函数。通过迭代这个过程，我们逐步接近最优参数解，从而训练出性能良好的模型。</p>
<p>例如，在神经网络训练中，我们需要最小化损失函数以找到最佳的模型参数。损失函数通常是一个高维的、非线性的、连续的函数，它将输入空间映射到输出空间。为了找到这个函数的最小值，我们需要计算梯度，即损失函数在某个点的偏导数。然后，我们可以沿着梯度的反方向更新模型参数，以逐步减小损失函数的值。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/10/10/CC04-%E5%81%8F%E5%AF%BC%E6%95%B0/" data-id="cm5m32i6100096obq0qcw5o38" data-title="预告" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%81%8F%E5%AF%BC%E6%95%B0/" rel="tag">偏导数</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/" rel="tag">反向传播</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/" rel="tag">微积分</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%A9%AC%E5%90%8C%E5%AD%A6/" rel="tag">马同学</a></li></ul>

    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/">微积分</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hessian%E7%9F%A9%E9%98%B5/" rel="tag">Hessian矩阵</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%8C%E9%98%B6%E4%BC%98%E5%8C%96/" rel="tag">二阶优化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%81%8F%E5%AF%BC%E6%95%B0/" rel="tag">偏导数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/" rel="tag">傅里叶变换</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%87%BD%E6%95%B0/" rel="tag">函数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%87%BD%E6%95%B0%E9%80%BC%E8%BF%91/" rel="tag">函数逼近</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/" rel="tag">反向传播</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%90%88%E9%9B%86%E4%BB%8B%E7%BB%8D/" rel="tag">合集介绍</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%9A%E5%8F%98%E9%87%8F%E5%87%BD%E6%95%B0/" rel="tag">多变量函数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AF%BC%E6%95%B0/" rel="tag">导数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AE%E5%88%86/" rel="tag">微分</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/" rel="tag">微积分</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0%E6%B3%95/" rel="tag">拉格朗日乘数法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%B6%E5%BA%8F%E5%88%86%E6%9E%90/" rel="tag">时序分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9E%81%E9%99%90/" rel="tag">极限</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/" rel="tag">梯度下降法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B/" rel="tag">概率模型</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A8%A1%E5%9E%8B%E7%AE%80%E5%8C%96/" rel="tag">模型简化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B3%B0%E5%8B%92%E5%85%AC%E5%BC%8F/" rel="tag">泰勒公式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">神经网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A7%AF%E5%88%86/" rel="tag">积分</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96/" rel="tag">约束优化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%9E%E7%BB%AD%E5%87%BD%E6%95%B0/" rel="tag">连续函数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99/" rel="tag">链式法则</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5/" rel="tag">雅可比矩阵</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%A2%84%E5%91%8A%E7%AF%87/" rel="tag">预告篇</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%A9%AC%E5%90%8C%E5%AD%A6/" rel="tag">马同学</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Hessian%E7%9F%A9%E9%98%B5/" style="font-size: 10px;">Hessian矩阵</a> <a href="/tags/%E4%BA%8C%E9%98%B6%E4%BC%98%E5%8C%96/" style="font-size: 10px;">二阶优化</a> <a href="/tags/%E5%81%8F%E5%AF%BC%E6%95%B0/" style="font-size: 10px;">偏导数</a> <a href="/tags/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/" style="font-size: 10px;">傅里叶变换</a> <a href="/tags/%E5%87%BD%E6%95%B0/" style="font-size: 10px;">函数</a> <a href="/tags/%E5%87%BD%E6%95%B0%E9%80%BC%E8%BF%91/" style="font-size: 10px;">函数逼近</a> <a href="/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/" style="font-size: 10px;">反向传播</a> <a href="/tags/%E5%90%88%E9%9B%86%E4%BB%8B%E7%BB%8D/" style="font-size: 15px;">合集介绍</a> <a href="/tags/%E5%A4%9A%E5%8F%98%E9%87%8F%E5%87%BD%E6%95%B0/" style="font-size: 10px;">多变量函数</a> <a href="/tags/%E5%AF%BC%E6%95%B0/" style="font-size: 10px;">导数</a> <a href="/tags/%E5%BE%AE%E5%88%86/" style="font-size: 10px;">微分</a> <a href="/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/" style="font-size: 20px;">微积分</a> <a href="/tags/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0%E6%B3%95/" style="font-size: 10px;">拉格朗日乘数法</a> <a href="/tags/%E6%97%B6%E5%BA%8F%E5%88%86%E6%9E%90/" style="font-size: 10px;">时序分析</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 20px;">机器学习</a> <a href="/tags/%E6%9E%81%E9%99%90/" style="font-size: 10px;">极限</a> <a href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/" style="font-size: 10px;">梯度下降法</a> <a href="/tags/%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">概率模型</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E7%AE%80%E5%8C%96/" style="font-size: 10px;">模型简化</a> <a href="/tags/%E6%B3%B0%E5%8B%92%E5%85%AC%E5%BC%8F/" style="font-size: 10px;">泰勒公式</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">神经网络</a> <a href="/tags/%E7%A7%AF%E5%88%86/" style="font-size: 10px;">积分</a> <a href="/tags/%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96/" style="font-size: 10px;">约束优化</a> <a href="/tags/%E8%BF%9E%E7%BB%AD%E5%87%BD%E6%95%B0/" style="font-size: 10px;">连续函数</a> <a href="/tags/%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99/" style="font-size: 10px;">链式法则</a> <a href="/tags/%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5/" style="font-size: 10px;">雅可比矩阵</a> <a href="/tags/%E9%A2%84%E5%91%8A%E7%AF%87/" style="font-size: 15px;">预告篇</a> <a href="/tags/%E9%A9%AC%E5%90%8C%E5%AD%A6/" style="font-size: 20px;">马同学</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/01/">January 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/12/">December 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/01/07/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2024/12/17/CC11-Hessian%E7%9F%A9%E9%98%B5/">预告</a>
          </li>
        
          <li>
            <a href="/2024/10/29/CC12-%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/">傅里叶变换：如何用一个公式读懂宇宙的语言？</a>
          </li>
        
          <li>
            <a href="/2024/10/24/CC10-%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5/">预告篇</a>
          </li>
        
          <li>
            <a href="/2024/10/22/CC09-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0%E6%B3%95/">预告</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>