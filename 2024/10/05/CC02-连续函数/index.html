<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>预告 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="讨论连续性如何影响机器学习中的优化问题。">
<meta property="og:type" content="article">
<meta property="og:title" content="预告">
<meta property="og:url" content="http://example.com/2024/10/05/CC02-%E8%BF%9E%E7%BB%AD%E5%87%BD%E6%95%B0/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="讨论连续性如何影响机器学习中的优化问题。">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-10-04T16:00:00.000Z">
<meta property="article:modified_time" content="2024-10-24T14:10:23.977Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="微积分">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="马同学">
<meta property="article:tag" content="连续函数">
<meta property="article:tag" content="函数逼近">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-CC02-连续函数" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/10/05/CC02-%E8%BF%9E%E7%BB%AD%E5%87%BD%E6%95%B0/" class="article-date">
  <time class="dt-published" datetime="2024-10-04T16:00:00.000Z" itemprop="datePublished">2024-10-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/">微积分</a>►<a class="article-category-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      预告
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>想象一下，如果你在绘制一条曲线，而这条曲线在某一点突然跳跃或断裂，那会是多么的突兀和不自然。<br>![[Pasted image 20241024205527.png]]<br>在微积分中，我们希望函数的图像就像一条平滑的绸带，无论我们如何放大，都不会看到任何的断裂或跳跃。这就是连续性的魅力所在。</p>
<p>今天，我们就来深入探讨一下，连续性在微积分中的重要性，以及它是如何影响我们对数学和世界的理解的。</p>
<h2 id="连续性的定义"><a href="#连续性的定义" class="headerlink" title="连续性的定义"></a>连续性的定义</h2><p>连续性在我们的日常生活中无处不在，它体现在许多细微之处。描述了事物在变化过程中的平滑过渡，没有间断或跳跃。</p>
<p>例如，温度计上显示的温度是连续变化的，不会出现突变；音乐播放时，音量的渐强或渐弱也是连续过渡的。</p>
<p>所以，连续性的定义也是简单而优雅：如果一个函数在某点的极限值等于该点的函数值，那么我们就说这个函数在这一点是连续的。</p>
<blockquote>
<p>这意味着，无论你多么接近这个点，函数的值都会无限接近于这一点的函数值。</p>
</blockquote>
<p><strong>用数学语言表达就是：</strong><br>设函数 $y=f(x)$ 在 $x_0$ 点的某一邻域内有定义，令：</p>
<script type="math/tex; mode=display">\Delta x = x-x_0 \ ,</script><script type="math/tex; mode=display">\Delta y = f(x_0+\Delta x)-f(x_0)</script><p>如果 $\lim<em>{\Delta x \to 0} \Delta y =$$\lim</em>{\Delta x \to 0} [f(x_0-\Delta x)-f(x_0)]=0$，那么称函数 $f(x)$ 在 $x_0$ 点连续。</p>
<blockquote>
<p>另一种定义：设函数 $y=f(x)$ 在 $x<em>0$ 点的某一邻域内有定义，若 $\lim</em>{ x \to x_0} [f(x)=f(x_0)$，就称函数 $f(x)$ 在 $x_0$ 点连续。</p>
</blockquote>
<p>而连续函数的定义：在区间上每一点都连续的函数，叫作在该区间上的<strong>连续函数</strong>，或者说函数在该区间连续。</p>
<h3 id="连续函数的性质"><a href="#连续函数的性质" class="headerlink" title="连续函数的性质"></a>连续函数的性质</h3><ol>
<li>和差性质：如果 $f(x)$ 和 $g(x)$ 在 $c$ 点连续，那么 $f(x)+g(x)$ 和 $f(x)-g(x)$ 也在 $c$ 点连续。</li>
<li>乘积性质：如果 $f(x)$ 和 $g(x)$ 在 $c$ 点连续，那么 $f(x)\cdot g(x)$ 也在 $c$ 点连续。</li>
<li>商的性质；如果 $f(x)$ 和 $g(x)$ 在 $c$ 点连续，且 $g(c) \neq 0$，那么 $\frac{f(x)}{g(x)}$ 也在 $c$ 点连续。</li>
<li>复合函数的连续性：如果 $f(x)$ 在 $u$ 点连续，$g(x)$ 在 $c$ 点连续，且 $g(c)=u$，那么复合函数 $f(g(x))$ 在 $c$ 点连续。</li>
</ol>
<h3 id="连续性的应用"><a href="#连续性的应用" class="headerlink" title="连续性的应用"></a>连续性的应用</h3><ol>
<li><strong>极限</strong>：连续性是极限存在的必要条件。如果一个函数在某点不连续，那么该点的极限可能不存在。</li>
<li><strong>导数</strong>：导数的定义涉及到极限，因此连续性是可导性的前提。一个函数在某点可导，那么它在该点必定连续。</li>
<li><strong>积分</strong>：连续函数的积分更容易计算，因为连续函数在闭区间上的积分可以通过定积分来求解。</li>
</ol>
<h2 id="连续性与机器学习"><a href="#连续性与机器学习" class="headerlink" title="连续性与机器学习"></a>连续性与机器学习</h2><p>在机器学习的广阔天地中，算法和模型如同繁星般繁多，而连续性则是连接这些繁星的银河。</p>
<h3 id="连续性：模型训练的稳定剂"><a href="#连续性：模型训练的稳定剂" class="headerlink" title="连续性：模型训练的稳定剂"></a>连续性：模型训练的稳定剂</h3><p>想象一下，如果一个模型在训练过程中像过山车一样忽上忽下，那会是多么令人抓狂。连续性在这里扮演了稳定剂的角色，确保了模型在训练过程中梯度的稳定性。这就像是给过山车装上了平滑的轨道，让模型能够平稳地朝着最优解前进。</p>
<h3 id="梯度消失？梯度爆炸？连续性来帮忙"><a href="#梯度消失？梯度爆炸？连续性来帮忙" class="headerlink" title="梯度消失？梯度爆炸？连续性来帮忙"></a>梯度消失？梯度爆炸？连续性来帮忙</h3><p>在深度学习的深渊中，梯度消失和梯度爆炸是两个让人头疼的问题。连续的激活函数和损失函数就像是潜水员的氧气瓶，帮助模型在深海中稳定地探索，避免了因为梯度问题而“窒息”。</p>
<h3 id="提高泛化能力，连续性功不可没"><a href="#提高泛化能力，连续性功不可没" class="headerlink" title="提高泛化能力，连续性功不可没"></a>提高泛化能力，连续性功不可没</h3><p>一个连续的模型在输入空间中的变化是平滑的，这意味着它不太可能对输入的微小变化产生极端的输出变化。这种平滑性提高了模型的泛化能力，让它在面对新的、未见过的数据时，也能做出准确的预测。</p>
<h3 id="连续性：优化算法的得力助手"><a href="#连续性：优化算法的得力助手" class="headerlink" title="连续性：优化算法的得力助手"></a>连续性：优化算法的得力助手</h3><p>许多优化算法，如梯度下降，依赖于目标函数的连续导数。连续性确保了这些算法可以有效地更新模型的参数，就像是给算法装上了精准的导航系统，指引它朝着损失函数的最小值稳步前进。</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>在微积分的世界里，连续性绘就了函数的流畅轨迹，奠定了极限与导数的坚实基础。而在机器学习的舞台上，它又成为了模型稳定性的守护者，优化算法的可靠伙伴，以及提升泛化能力和鲁棒性的秘诀。正是连续性，让微积分的力量在机器学习领域中绽放光彩。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/10/05/CC02-%E8%BF%9E%E7%BB%AD%E5%87%BD%E6%95%B0/" data-id="cm5m32i5y00046obq325fas1y" data-title="预告" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%87%BD%E6%95%B0%E9%80%BC%E8%BF%91/" rel="tag">函数逼近</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/" rel="tag">微积分</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BF%9E%E7%BB%AD%E5%87%BD%E6%95%B0/" rel="tag">连续函数</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%A9%AC%E5%90%8C%E5%AD%A6/" rel="tag">马同学</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2024/10/08/CC03-%E5%AF%BC%E6%95%B0/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          预告
        
      </div>
    </a>
  
  
    <a href="/2024/10/03/CC01-%E6%9E%81%E9%99%90%E4%B8%8E%E5%87%BD%E6%95%B0/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">预告</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/">微积分</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BE%AE%E7%A7%AF%E5%88%86/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hessian%E7%9F%A9%E9%98%B5/" rel="tag">Hessian矩阵</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%8C%E9%98%B6%E4%BC%98%E5%8C%96/" rel="tag">二阶优化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%81%8F%E5%AF%BC%E6%95%B0/" rel="tag">偏导数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/" rel="tag">傅里叶变换</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%87%BD%E6%95%B0/" rel="tag">函数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%87%BD%E6%95%B0%E9%80%BC%E8%BF%91/" rel="tag">函数逼近</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/" rel="tag">反向传播</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%90%88%E9%9B%86%E4%BB%8B%E7%BB%8D/" rel="tag">合集介绍</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%9A%E5%8F%98%E9%87%8F%E5%87%BD%E6%95%B0/" rel="tag">多变量函数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AF%BC%E6%95%B0/" rel="tag">导数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AE%E5%88%86/" rel="tag">微分</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/" rel="tag">微积分</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0%E6%B3%95/" rel="tag">拉格朗日乘数法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%B6%E5%BA%8F%E5%88%86%E6%9E%90/" rel="tag">时序分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9E%81%E9%99%90/" rel="tag">极限</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/" rel="tag">梯度下降法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B/" rel="tag">概率模型</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A8%A1%E5%9E%8B%E7%AE%80%E5%8C%96/" rel="tag">模型简化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B3%B0%E5%8B%92%E5%85%AC%E5%BC%8F/" rel="tag">泰勒公式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">神经网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A7%AF%E5%88%86/" rel="tag">积分</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96/" rel="tag">约束优化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%9E%E7%BB%AD%E5%87%BD%E6%95%B0/" rel="tag">连续函数</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99/" rel="tag">链式法则</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5/" rel="tag">雅可比矩阵</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%A2%84%E5%91%8A%E7%AF%87/" rel="tag">预告篇</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%A9%AC%E5%90%8C%E5%AD%A6/" rel="tag">马同学</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Hessian%E7%9F%A9%E9%98%B5/" style="font-size: 10px;">Hessian矩阵</a> <a href="/tags/%E4%BA%8C%E9%98%B6%E4%BC%98%E5%8C%96/" style="font-size: 10px;">二阶优化</a> <a href="/tags/%E5%81%8F%E5%AF%BC%E6%95%B0/" style="font-size: 10px;">偏导数</a> <a href="/tags/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/" style="font-size: 10px;">傅里叶变换</a> <a href="/tags/%E5%87%BD%E6%95%B0/" style="font-size: 10px;">函数</a> <a href="/tags/%E5%87%BD%E6%95%B0%E9%80%BC%E8%BF%91/" style="font-size: 10px;">函数逼近</a> <a href="/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/" style="font-size: 10px;">反向传播</a> <a href="/tags/%E5%90%88%E9%9B%86%E4%BB%8B%E7%BB%8D/" style="font-size: 15px;">合集介绍</a> <a href="/tags/%E5%A4%9A%E5%8F%98%E9%87%8F%E5%87%BD%E6%95%B0/" style="font-size: 10px;">多变量函数</a> <a href="/tags/%E5%AF%BC%E6%95%B0/" style="font-size: 10px;">导数</a> <a href="/tags/%E5%BE%AE%E5%88%86/" style="font-size: 10px;">微分</a> <a href="/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/" style="font-size: 20px;">微积分</a> <a href="/tags/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0%E6%B3%95/" style="font-size: 10px;">拉格朗日乘数法</a> <a href="/tags/%E6%97%B6%E5%BA%8F%E5%88%86%E6%9E%90/" style="font-size: 10px;">时序分析</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 20px;">机器学习</a> <a href="/tags/%E6%9E%81%E9%99%90/" style="font-size: 10px;">极限</a> <a href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/" style="font-size: 10px;">梯度下降法</a> <a href="/tags/%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">概率模型</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E7%AE%80%E5%8C%96/" style="font-size: 10px;">模型简化</a> <a href="/tags/%E6%B3%B0%E5%8B%92%E5%85%AC%E5%BC%8F/" style="font-size: 10px;">泰勒公式</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">神经网络</a> <a href="/tags/%E7%A7%AF%E5%88%86/" style="font-size: 10px;">积分</a> <a href="/tags/%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96/" style="font-size: 10px;">约束优化</a> <a href="/tags/%E8%BF%9E%E7%BB%AD%E5%87%BD%E6%95%B0/" style="font-size: 10px;">连续函数</a> <a href="/tags/%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99/" style="font-size: 10px;">链式法则</a> <a href="/tags/%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5/" style="font-size: 10px;">雅可比矩阵</a> <a href="/tags/%E9%A2%84%E5%91%8A%E7%AF%87/" style="font-size: 15px;">预告篇</a> <a href="/tags/%E9%A9%AC%E5%90%8C%E5%AD%A6/" style="font-size: 20px;">马同学</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/01/">January 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/12/">December 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/01/07/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2024/12/17/CC11-Hessian%E7%9F%A9%E9%98%B5/">预告</a>
          </li>
        
          <li>
            <a href="/2024/10/29/CC12-%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/">傅里叶变换：如何用一个公式读懂宇宙的语言？</a>
          </li>
        
          <li>
            <a href="/2024/10/24/CC10-%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5/">预告篇</a>
          </li>
        
          <li>
            <a href="/2024/10/22/CC09-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0%E6%B3%95/">预告</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>